{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK1: Collapsed Gibbs Sampler for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "K = 2\n",
    "N_iters = 500\n",
    "alpha=float(5)/float(K)\n",
    "dirichlet_alpha = alpha*np.ones(K)\n",
    "#print(dirichlet_alpha.shape)\n",
    "beta = 0.01\n",
    "dirichlet_beta = beta*np.ones(K)\n",
    "#print(dirichlet_beta.shape)\n",
    "parent_dir = '/Users/sahiltyagi/Downloads/pp4data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_preprocessing(dir_name):\n",
    "    directory = os.path.join(parent_dir, dir_name)\n",
    "    listfiles = os.listdir(directory)\n",
    "    #print(listfiles)\n",
    "    N_words = 0\n",
    "    D = (len(listfiles) - 1)\n",
    "    # unique words \n",
    "    V = 0\n",
    "    word_indices = []\n",
    "    unique_word_indices = []\n",
    "    doc_indices = []\n",
    "    # topic indices\n",
    "    z_indices = []\n",
    "    \n",
    "    for filename in listfiles:\n",
    "        if filename != 'index.csv':\n",
    "            #print(filename)\n",
    "            \n",
    "            word_count = {}\n",
    "            \n",
    "            f = open(directory + '/' + filename, 'r')\n",
    "            for line in f:\n",
    "                N_words = N_words + len(line.split())\n",
    "                for word in line.split():\n",
    "                    \n",
    "                    if word not in word_count.keys():\n",
    "                        word_count[word] = 1\n",
    "                        \n",
    "                    elif word in word_count.keys():\n",
    "                        word_count[word] = word_count[word] + 1\n",
    "                    \n",
    "                    if word not in word_indices:\n",
    "                        V = V + 1\n",
    "                        unique_word_indices.append(word)\n",
    "                    \n",
    "                    word_indices.append(word)\n",
    "                    doc_indices.append(str(filename))\n",
    "                    topic = random.randint(0,(K-1))\n",
    "                    z_indices.append(topic)\n",
    "                    \n",
    "            \n",
    "            f.close()\n",
    "    \n",
    "    word_indices = np.array(word_indices)\n",
    "    doc_indices = np.array(doc_indices)\n",
    "    z_indices = np.array(z_indices)\n",
    "    return N_words, word_indices, unique_word_indices, doc_indices, z_indices, V, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words 459\n",
      "number of UNIQUE words 5\n",
      "(459,)\n",
      "(459,)\n",
      "(459,)\n"
     ]
    }
   ],
   "source": [
    "N_words, word_indices, unique_word_indices, doc_indices, z_indices, V, D = do_preprocessing('artificial')\n",
    "print('number of words ' + str(N_words))\n",
    "print('number of UNIQUE words ' + str(V))\n",
    "print(word_indices.shape)\n",
    "print(doc_indices.shape)\n",
    "print(z_indices.shape)\n",
    "#print(z_indices)\n",
    "#print(z_indices[3,])\n",
    "#print(doc_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapsed_gibbs_sampler(K, N_iters, alpha, beta, dir_name):\n",
    "    N_words, word_indices, unique_word_indices, doc_indices, z_indices, V, D  = do_preprocessing(\n",
    "        dir_name)\n",
    "    \n",
    "    print('number of words ' + str(N_words))\n",
    "    print('number of UNIQUE words ' + str(V))\n",
    "    print('number of documents ' + str(D))\n",
    "\n",
    "    pi=[i for i in range(0, N_words)]\n",
    "    pi=np.random.permutation(pi)\n",
    "\n",
    "    #intitilaize probabilities for the topics to zero\n",
    "    probability = []\n",
    "    for i in range(0,K):\n",
    "        probability.append(0.0)\n",
    "    \n",
    "    probability = np.array(probability)\n",
    "    #print(probability.shape)\n",
    "    \n",
    "    C_d = np.zeros((D,K))\n",
    "    C_t = np.zeros((K,V))\n",
    "    print('C_d shape ' + str(C_d.shape))\n",
    "    print('C_t shape ' + str(C_t.shape))\n",
    "    #print(C_d[0][1])\n",
    "    \n",
    "    topics_rep_C_d = np.zeros((D,K))\n",
    "    \n",
    "    for i in range(0, N_words):\n",
    "        #print('doc index ' + str(doc_indices[i,]))\n",
    "        #print('topic index ' + str(z_indices[i,]))\n",
    "        C_d[int(doc_indices[i,]) - 1][int(z_indices[i,])] += 1\n",
    "        C_t[z_indices[i,]][unique_word_indices.index(word_indices[i,])] += 1\n",
    "        \n",
    "    #print('C_d matrix ' + str(C_d))\n",
    "    #print('C_t matrix ' + str(C_t))\n",
    "    #print('probability vector ' + str(probability))\n",
    "    \n",
    "    for i in range(0, N_iters):\n",
    "        for j in range(0, N_words):\n",
    "            word = word_indices[pi[j],]\n",
    "            topic = z_indices[pi[j],]\n",
    "            doc = doc_indices[pi[j],]\n",
    "            \n",
    "            C_d[int(doc) -1][int(topic)] -= 1\n",
    "            C_t[int(topic), unique_word_indices.index(word)] -= 1\n",
    "            \n",
    "            for k in range(0, K):\n",
    "                \n",
    "                sum_doc_topics = K*alpha + np.sum(C_d[int(doc) - 1,:])\n",
    "                #print('sum_doc_topics ' + str(sum_doc_topics))\n",
    "                #print('numerator ' + str(C_d[int(doc)-1, int(topic)] + alpha))\n",
    "                #print('term1 ' + str(C_d[int(doc)-1, int(topic)]))\n",
    "                #print('term2 ' + str(alpha))\n",
    "                topic_distribution = (C_d[int(doc)-1, int(topic)] + alpha)/sum_doc_topics\n",
    "                \n",
    "                topics_rep_C_d[int(doc)-1][int(topic)] = topic_distribution\n",
    "                \n",
    "                sum_topic_words = V*beta + np.sum(C_t[int(topic),:])\n",
    "                word_distribution = (C_t[int(topic), unique_word_indices.index(word)] + beta)/sum_topic_words\n",
    "                #print('topic dist ' + str(topic_distribution))\n",
    "                #print('word dist ' + str(word_distribution))\n",
    "                \n",
    "                probability[k,] = topic_distribution * word_distribution\n",
    "                \n",
    "            #print('##############################')\n",
    "            #print(probability)\n",
    "            probability = probability/sum(probability)\n",
    "            topic = np.random.choice([q for q in range(0, K)], p = probability)\n",
    "            z_indices[pi[j],] = topic\n",
    "            C_d[int(doc) -1][int(topic)] += 1\n",
    "            C_t[int(topic), unique_word_indices.index(word)] += 1\n",
    "            \n",
    "    return z_indices, C_d, C_t, unique_word_indices, topics_rep_C_d, V, N_words, doc_indices, word_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ARTIFICIAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words 459\n",
      "number of UNIQUE words 5\n",
      "number of documents 10\n",
      "C_d shape (10, 2)\n",
      "C_t shape (2, 5)\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "N_iters = 500\n",
    "alpha = float(5)/float(K)\n",
    "dirichlet_alpha = alpha*np.ones(K)\n",
    "#print(dirichlet_alpha.shape)\n",
    "beta = float(0.01)\n",
    "dirichlet_beta = beta*np.ones(K)\n",
    "#print(dirichlet_beta.shape)\n",
    "\n",
    "z_indices, C_d, C_t, unique_word_indices, topics_rep_C_d, V, N_words, doc_indices, word_indices = collapsed_gibbs_sampler(\n",
    "    K, N_iters, alpha, beta, 'artificial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21. 26.]\n",
      " [26. 26.]\n",
      " [18. 16.]\n",
      " [19. 39.]\n",
      " [18. 16.]\n",
      " [38. 45.]\n",
      " [49. 37.]\n",
      " [17.  9.]\n",
      " [ 1.  2.]\n",
      " [18. 18.]]\n",
      "[[50. 32. 35. 75. 33.]\n",
      " [35. 37. 39. 88. 35.]]\n",
      "(10, 2)\n",
      "(2, 5)\n",
      "%%%%%%%%%%%%%%% For Topic 0\n",
      "word loan and count 50.0\n",
      "word dollars and count 32.0\n",
      "word water and count 35.0\n",
      "word bank and count 75.0\n",
      "word river and count 33.0\n",
      "%%%%%%%%%%%%%%% For Topic 1\n",
      "word loan and count 35.0\n",
      "word dollars and count 37.0\n",
      "word water and count 39.0\n",
      "word bank and count 88.0\n",
      "word river and count 35.0\n"
     ]
    }
   ],
   "source": [
    "artificial_C_d = C_d\n",
    "artificial_C_t = C_t\n",
    "artificial_z_indices = z_indices\n",
    "artificial_topics_rep_C_d = topics_rep_C_d\n",
    "artificial_unique_word_indices = unique_word_indices\n",
    "artificial_V = V\n",
    "artificial_N_words = N_words\n",
    "artificial_doc_indices = doc_indices\n",
    "artificial_word_indices = word_indices\n",
    "\n",
    "\n",
    "print(artificial_C_d)\n",
    "print(artificial_C_t)\n",
    "print(artificial_C_d.shape)\n",
    "print(artificial_C_t.shape)\n",
    "f = open(parent_dir + 'artificial_topicwords.csv', 'w')\n",
    "f.write('topic,word,count\\n')\n",
    "for k in range(0, K):\n",
    "    print('%%%%%%%%%%%%%%% For Topic ' + str(k))\n",
    "    word_topic_vector = artificial_C_t[k,:]\n",
    "    for ix in range(0, word_topic_vector.shape[0]):\n",
    "        print('word ' + str(unique_word_indices[ix]) + ' and count ' + str(word_topic_vector[ix,]))\n",
    "        f.write(str(k) + ',' + str(unique_word_indices[ix]) + ',' + str(int(word_topic_vector[ix,])) + '\\n')\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR 20NEWSGROUPS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words 8013\n",
      "number of UNIQUE words 405\n",
      "number of documents 200\n",
      "C_d shape (200, 20)\n",
      "C_t shape (20, 405)\n"
     ]
    }
   ],
   "source": [
    "K = 20\n",
    "N_iters = 500\n",
    "alpha = float(5)/float(K)\n",
    "dirichlet_alpha = alpha*np.ones(K)\n",
    "#print(dirichlet_alpha.shape)\n",
    "beta = float(0.01)\n",
    "dirichlet_beta = beta*np.ones(K)\n",
    "#print(dirichlet_beta.shape)\n",
    "\n",
    "z_indices, C_d, C_t, unique_word_indices, topics_rep_C_d, V, N_words, doc_indices, word_indices = collapsed_gibbs_sampler(\n",
    "    K, N_iters, alpha, beta, '20newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 1. 0.]\n",
      " [3. 2. 3. ... 4. 4. 9.]\n",
      " [1. 0. 1. ... 0. 2. 0.]\n",
      " ...\n",
      " [1. 0. 1. ... 1. 0. 0.]\n",
      " [2. 4. 3. ... 5. 1. 0.]\n",
      " [3. 2. 4. ... 1. 5. 1.]]\n",
      "[[5. 2. 1. ... 1. 0. 0.]\n",
      " [3. 2. 0. ... 0. 0. 2.]\n",
      " [5. 2. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [8. 1. 1. ... 1. 2. 0.]\n",
      " [8. 0. 1. ... 1. 0. 0.]\n",
      " [5. 0. 0. ... 0. 1. 1.]]\n",
      "(200, 20)\n",
      "(20, 405)\n",
      "%%%%%%%%%%%%%%% For Topic 0\n",
      "%%%%%%%%%%%%%%% For Topic 1\n",
      "%%%%%%%%%%%%%%% For Topic 2\n",
      "%%%%%%%%%%%%%%% For Topic 3\n",
      "%%%%%%%%%%%%%%% For Topic 4\n",
      "%%%%%%%%%%%%%%% For Topic 5\n",
      "%%%%%%%%%%%%%%% For Topic 6\n",
      "%%%%%%%%%%%%%%% For Topic 7\n",
      "%%%%%%%%%%%%%%% For Topic 8\n",
      "%%%%%%%%%%%%%%% For Topic 9\n",
      "%%%%%%%%%%%%%%% For Topic 10\n",
      "%%%%%%%%%%%%%%% For Topic 11\n",
      "%%%%%%%%%%%%%%% For Topic 12\n",
      "%%%%%%%%%%%%%%% For Topic 13\n",
      "%%%%%%%%%%%%%%% For Topic 14\n",
      "%%%%%%%%%%%%%%% For Topic 15\n",
      "%%%%%%%%%%%%%%% For Topic 16\n",
      "%%%%%%%%%%%%%%% For Topic 17\n",
      "%%%%%%%%%%%%%%% For Topic 18\n",
      "%%%%%%%%%%%%%%% For Topic 19\n"
     ]
    }
   ],
   "source": [
    "news_C_d = C_d\n",
    "news_C_t = C_t\n",
    "news_z_indices = z_indices\n",
    "news_topics_rep_C_d = topics_rep_C_d\n",
    "news_unique_word_indices = unique_word_indices\n",
    "news_v = V\n",
    "news_N_words = N_words\n",
    "news_doc_indices = doc_indices\n",
    "news_word_indices = word_indices\n",
    "\n",
    "#print(unique_word_indices)\n",
    "\n",
    "print(news_C_d)\n",
    "print(news_C_t)\n",
    "print(news_C_d.shape)\n",
    "print(news_C_t.shape)\n",
    "f = open(parent_dir + '20newsgroups_topicwords.csv', 'w')\n",
    "f.write('topic,word,count\\n')\n",
    "for k in range(0, K):\n",
    "    print('%%%%%%%%%%%%%%% For Topic ' + str(k))\n",
    "    word_topic_vector = news_C_t[k,:]\n",
    "    for ix in range(0, word_topic_vector.shape[0]):\n",
    "        #print('word ' + str(unique_word_indices[ix]) + ' and count ' + str(word_topic_vector[ix,]))\n",
    "        f.write(str(k) + ',' + str(news_unique_word_indices[ix]) + ',' + str(int(word_topic_vector[ix,])) + '\\n')\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 2: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR ARTIFICIAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_representation(topics_rep_C_d, V, doc_indices, word_indices, unique_word_indices, N_words):\n",
    "    \n",
    "    bag_of_words = np.zeros((topics_rep_C_d.shape[0], V))\n",
    "    for i in range(0, N_words):\n",
    "        bag_of_words[int(doc_indices[i,]) - 1][unique_word_indices.index(word_indices[i,])] += 1\n",
    "        \n",
    "    #print(bag_of_words)\n",
    "    #print(np.sum(bag_of_words))\n",
    "    return bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words [[13. 18.  1. 14.  1.]\n",
      " [ 4.  1. 11. 21. 15.]\n",
      " [11. 11.  3.  7.  2.]\n",
      " [ 3.  5. 20. 17. 13.]\n",
      " [13.  7.  0. 11.  3.]\n",
      " [ 4.  4. 19. 38. 18.]\n",
      " [31. 20.  5. 28.  2.]\n",
      " [ 2.  0.  5. 14.  5.]\n",
      " [ 1.  2.  0.  0.  0.]\n",
      " [ 3.  1. 10. 13.  9.]]\n",
      "doc topic represent [[0.46078431 0.53921569]\n",
      " [0.50892857 0.47321429]\n",
      " [0.51315789 0.46052632]\n",
      " [0.34677419 0.62096774]\n",
      " [0.46052632 0.48684211]\n",
      " [0.46551724 0.53448276]\n",
      " [0.57222222 0.41666667]\n",
      " [0.61666667 0.35      ]\n",
      " [0.35714286 0.5       ]\n",
      " [0.4875     0.4875    ]]\n"
     ]
    }
   ],
   "source": [
    "artificial_bag_of_words = bag_of_words_representation(artificial_topics_rep_C_d, artificial_V, \n",
    "                                                      artificial_doc_indices, artificial_word_indices, \n",
    "                                                      artificial_unique_word_indices, artificial_N_words)\n",
    "# print(artificial_bag_of_words.shape)\n",
    "# print(artificial_topics_rep_C_d.shape)\n",
    "print('bag of words ' + str(artificial_bag_of_words))\n",
    "print('doc topic represent ' + str(artificial_topics_rep_C_d))\n",
    "np.savetxt(parent_dir + 'artificial_doc_topics.csv', artificial_topics_rep_C_d, delimiter=',')\n",
    "np.savetxt(parent_dir + 'artificial_bag_of_words.csv', artificial_bag_of_words, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 405)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "news_bag_of_words = bag_of_words_representation(news_topics_rep_C_d, news_v, news_doc_indices, news_word_indices, \n",
    "                                                news_unique_word_indices, news_N_words)\n",
    "print(news_bag_of_words.shape)\n",
    "print(news_topics_rep_C_d.shape)\n",
    "# print('bag of words ' + str(news_bag_of_words))\n",
    "# print('doc topic represent ' + str(news_topics_rep_C_d))\n",
    "np.savetxt(parent_dir + 'news_doc_topics.csv', news_topics_rep_C_d, delimiter=',')\n",
    "np.savetxt(parent_dir + 'news_bag_of_words.csv', news_bag_of_words, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_matrix(data_feature):\n",
    "    new_irls=np.ones((len(data_feature),len(data_feature[0])+1))\n",
    "    flag=np.fliplr(data_feature)\n",
    "\n",
    "    for i in range(0,len(flag)):\n",
    "        for j in range(0,len(flag[i])):\n",
    "            new_irls[i][j]=flag[i][j]\n",
    "\n",
    "    new_irls=np.fliplr(new_irls)\n",
    "    return new_irls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_randomness_read_input_file_with_added_feature(feature_file, label_file, dataset, fraction):\n",
    "    input_feature = np.loadtxt(open(parent_dir + feature_file, \"rb\"), delimiter=\",\")\n",
    "    input_label = np.loadtxt(open(parent_dir + dataset + '/' + label_file, \"rb\"), delimiter=\",\")\n",
    "    \n",
    "    #getting rid of document document name in input_label as we only need topic number\n",
    "    input_label = input_label[:,1]\n",
    "    \n",
    "    print(input_label.shape)\n",
    "    print(input_feature.shape)\n",
    "    \n",
    "    #added a vector column of 1\n",
    "#     input_feature = np.append(input_feature, np.ones([len(input_feature),1]), axis=1)\n",
    "#     print(input_feature.shape)\n",
    "\n",
    "    input_feature = adjust_matrix(input_feature)\n",
    "    train_set_size = input_feature.shape[0]\n",
    "    \n",
    "    final_trainset_size = int(frac * train_set_size)\n",
    "    \n",
    "    input_feature = input_feature[0:final_trainset_size,]\n",
    "    input_label = input_label[0:final_trainset_size]\n",
    "    \n",
    "    print('^^^^^^^^^^^^^^^^^^^^^^^^^^')\n",
    "    print(input_label.shape)\n",
    "    print(input_feature.shape)\n",
    "    \n",
    "    test_set_size = int(input_feature.shape[0]/3)\n",
    "    train_set_size = int(input_feature.shape[0] - test_set_size)\n",
    "    ctr = 0\n",
    "    test_set_indices = []\n",
    "    \n",
    "    ix = 0\n",
    "    while len(test_set_indices) < test_set_size:\n",
    "        if ix not in test_set_indices:\n",
    "            test_set_indices.append(ix)\n",
    "        ix = ix + 1\n",
    "    #print('len test_set_indices ' + str(len(test_set_indices)))\n",
    "        \n",
    "    all_indices = []\n",
    "    for i in range(0, input_feature.shape[0]):\n",
    "        all_indices.append(i)\n",
    "    #print('len all indices ' + str(len(all_indices)))\n",
    "        \n",
    "    train_set_indices = []\n",
    "    for ix in all_indices:\n",
    "        if ix not in test_set_indices:\n",
    "            train_set_indices.append(ix)\n",
    "    #print('len train_set_indices ' + str(len(train_set_indices)))\n",
    "        \n",
    "    testset_features = np.take(input_feature, test_set_indices, axis=0)\n",
    "    testset_label = np.take(input_label, test_set_indices, axis=0)\n",
    "    print('test set..')\n",
    "    print(testset_features.shape)\n",
    "    print(testset_label.shape)\n",
    "    \n",
    "    trainset_features = np.take(input_feature, train_set_indices, axis=0)\n",
    "    trainset_label = np.take(input_label, train_set_indices, axis=0)\n",
    "    print('train set..')\n",
    "    print(trainset_features.shape)\n",
    "    print(trainset_label.shape)\n",
    "    \n",
    "    return trainset_features, trainset_label, testset_features, testset_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_and_error(a, testset_label):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ix in range(0, a.shape[0]):\n",
    "        if a[ix] >= 0:\n",
    "            y_pred = 1\n",
    "        else:\n",
    "            y_pred = 0\n",
    "        \n",
    "        if y_pred == testset_label[ix]:\n",
    "            correct = correct + 1\n",
    "        \n",
    "        total = total + 1\n",
    "    \n",
    "    accuracy = float(correct)/float(total)\n",
    "    error = 1 - accuracy\n",
    "    print('accuracy is ' + str(accuracy))\n",
    "    print('error is ' + str(1 - accuracy))\n",
    "    return accuracy, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from numpy import exp\n",
    "\n",
    "def newtons_method(trainset_features, trainset_label, testset_features, testset_label):\n",
    "    \n",
    "    w_vector_list = []\n",
    "    runtime_list = []\n",
    "    \n",
    "    w = np.zeros([trainset_features.shape[1],1])\n",
    "    #print(w.shape)\n",
    "    alpha = 0.01\n",
    "    w_n_norm = np.linalg.norm(w)\n",
    "    stop_criteria = 10.0\n",
    "    iterations = 0\n",
    "    trainset_label = trainset_label.reshape((trainset_label.shape[0],1))\n",
    "    print('trainset shape' + str(trainset_features.shape))\n",
    "    print('train label shape' + str(trainset_label.shape))\n",
    "    print('testset shape' + str(testset_features.shape))\n",
    "    print('test label shape' + str(testset_label.shape))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while iterations < 500:\n",
    "        a_list = []\n",
    "        \n",
    "        for ix in range(0, trainset_features.shape[0]):\n",
    "            record = trainset_features[ix,:]\n",
    "            record = record.reshape([1,trainset_features.shape[1]])\n",
    "            #print('record shape ' + str(record.shape))\n",
    "            mew_a = np.matmul(record, w)\n",
    "            #print('mew_a shape ' + str(mew_a.shape))\n",
    "            S_n = alpha * np.identity(trainset_features.shape[1])\n",
    "            #print('S_n shape ' + str(S_n.shape))\n",
    "            sigma_a2 = np.matmul(record, np.matmul(S_n, np.transpose(record)))\n",
    "            #print('sigma_a2 shape ' + str(sigma_a2.shape))\n",
    "            \n",
    "            a = float(mew_a) / float((math.sqrt(1 + (math.pi*sigma_a2)/8)))\n",
    "            #print(a)\n",
    "            \n",
    "            a_list.append(a)\n",
    "            \n",
    "        a_val = np.array(a_list)\n",
    "        #print(a_val.shape)\n",
    "        \n",
    "        \n",
    "        y_1 = 1 / (1 + exp(-a_val))\n",
    "        #print('y_1 vector is...')\n",
    "        #print(y_1)\n",
    "        #print('y1 shape is ' + str(y_1.shape))\n",
    "        y_0 = 1 - y_1\n",
    "        #print('y0 shape is ' + str(y_0.shape))\n",
    "        \n",
    "        y_1 = y_1.reshape((y_1.shape[0],1))\n",
    "        y_0 = y_0.reshape((y_0.shape[0],1))\n",
    "        \n",
    "        Rmat = np.matmul(y_1, np.transpose(y_0))\n",
    "        Rmat = np.diag(Rmat)\n",
    "        #print('R matrix shape ' + str(Rmat.shape))\n",
    "        identity_mat = np.identity(Rmat.shape[0])\n",
    "        Rmat = np.multiply(Rmat, identity_mat)\n",
    "        #print('R matrix diagonalized shape ' + str(Rmat.shape))\n",
    "        #print(Rmat)\n",
    "        \n",
    "        alpha_I = alpha * np.identity(trainset_features.shape[1])\n",
    "        #print('alpha_I ' + str(alpha_I.shape))\n",
    "        Hessian = alpha_I + np.matmul(np.transpose(trainset_features), np.matmul(Rmat, trainset_features))\n",
    "        Hessian_inverse = np.linalg.inv(Hessian)\n",
    "        #print('Hessian_inv shape ' + str(Hessian_inverse.shape))\n",
    "        #print('w shape again ' + str(w.shape))\n",
    "        g = np.matmul(np.transpose(trainset_features), y_1 - trainset_label) + alpha*w\n",
    "        #print('g shape is ' + str(g.shape))\n",
    "        w = w - np.matmul(Hessian_inverse, g)\n",
    "        #print(w.shape)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        w_vector_list.append(w)\n",
    "        runtime_list.append(float(end_time - start_time))\n",
    "        \n",
    "        w_n_plus_1_norm = np.linalg.norm(w)\n",
    "        # evaluate stop criterion here...\n",
    "        \n",
    "        stop_criteria = abs(w_n_plus_1_norm - w_n_norm)/w_n_norm\n",
    "        #print('stop criterion threshold value is ' + str(stop_criteria))\n",
    "        if stop_criteria < 0.001:\n",
    "            print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............')\n",
    "            break\n",
    "        \n",
    "        w_n_norm = np.linalg.norm(w)\n",
    "        iterations = iterations + 1\n",
    "        print('iteration ' + str(iterations))\n",
    "        \n",
    "    #print(w)\n",
    "    # evaluating on the test set now...\n",
    "    print('w_vector_list length is ' + str(len(w_vector_list)))\n",
    "    #print(w_vector_list)\n",
    "    error_across_updates = []\n",
    "    for w_val in w_vector_list:\n",
    "        testset_a = []\n",
    "        for ix in range(0, testset_features.shape[0]):\n",
    "            record = testset_features[ix,:]\n",
    "            record = record.reshape([1,testset_features.shape[1]])\n",
    "            #print('record shape ' + str(record.shape))\n",
    "            mew_a = np.matmul(record, w_val)\n",
    "            #print('mew_a shape ' + str(mew_a.shape))\n",
    "            S_n = alpha * np.identity(testset_features.shape[1])\n",
    "            #print('S_n shape ' + str(S_n.shape))\n",
    "            sigma_a2 = np.matmul(record, np.matmul(S_n, np.transpose(record)))\n",
    "            #print('sigma_a2 shape ' + str(sigma_a2.shape))\n",
    "            \n",
    "            a = float(mew_a) / float((math.sqrt(1 + (math.pi*sigma_a2)/8)))\n",
    "            #print(a)\n",
    "            testset_a.append(a)\n",
    "            \n",
    "        testset_a = np.array(testset_a)\n",
    "        _, error = calculate_accuracy_and_error(testset_a, testset_label)\n",
    "        error_across_updates.append(error)\n",
    "        \n",
    "    return error_across_updates, runtime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 2)\n",
      "test set..\n",
      "(3, 3)\n",
      "(3,)\n",
      "train set..\n",
      "(7, 3)\n",
      "(7,)\n",
      "trainset shape(7, 3)\n",
      "train label shape(7, 1)\n",
      "testset shape(3, 3)\n",
      "test label shape(3,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 4\n",
      "accuracy is 1.0\n",
      "error is 0.0\n",
      "accuracy is 1.0\n",
      "error is 0.0\n",
      "accuracy is 1.0\n",
      "error is 0.0\n",
      "accuracy is 1.0\n",
      "error is 0.0\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "[0.0003399848937988281, 0.0011909008026123047, 0.0015189647674560547, 0.0020461082458496094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "    'artificial_doc_topics.csv', 'index.csv', 'artificial', 1.0)\n",
    "err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "#print(acc)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 5)\n",
      "test set..\n",
      "(3, 6)\n",
      "(3,)\n",
      "train set..\n",
      "(7, 6)\n",
      "(7,)\n",
      "trainset shape(7, 6)\n",
      "train label shape(7, 1)\n",
      "testset shape(3, 6)\n",
      "test label shape(3,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 10\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "accuracy is 0.0\n",
      "error is 1.0\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "[0.0003631114959716797, 0.001157999038696289, 0.0015621185302734375, 0.0021619796752929688, 0.002480030059814453, 0.0028259754180908203, 0.003281116485595703, 0.0035941600799560547, 0.003928184509277344, 0.004256010055541992]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "    'artificial_bag_of_words.csv', 'index.csv', 'artificial', 1.0)\n",
    "err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "#print(acc)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_newtons_method(feature_file, label_file, dataset):\n",
    "    trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "        feature_file, label_file, dataset, 1.0)\n",
    "    testset_label = testset_label.reshape((testset_label.shape[0],1))\n",
    "    \n",
    "    repeats = 3\n",
    "    for i in range(0, repeats):\n",
    "        error_across_updates, runtime_list = newtons_method(\n",
    "            trainset_features, trainset_label, testset_features, testset_label)\n",
    "        print('error_across_updates length ' + str(len(error_across_updates)))\n",
    "        print('runtime_list length ' + str(len(runtime_list)))\n",
    "        \n",
    "    plt.plot(runtime_list, error_across_updates)\n",
    "    plt.xlabel('run time (sec)')\n",
    "    plt.ylabel('Test error')\n",
    "    plt.title('Dataset ' + dataset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_newtons_method('artificial_doc_topics.csv', 'index.csv', 'artificial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 20)\n",
      "test set..\n",
      "(66, 21)\n",
      "(66,)\n",
      "train set..\n",
      "(134, 21)\n",
      "(134,)\n",
      "trainset shape(134, 21)\n",
      "train label shape(134, 1)\n",
      "testset shape(66, 21)\n",
      "test label shape(66,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0.4545454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "    'news_doc_topics.csv', 'index.csv', '20newsgroups', 1.0)\n",
    "err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "#print(acc)\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 405)\n",
      "test set..\n",
      "(66, 406)\n",
      "(66,)\n",
      "train set..\n",
      "(134, 406)\n",
      "(134,)\n",
      "trainset shape(134, 406)\n",
      "train label shape(134, 1)\n",
      "testset shape(66, 406)\n",
      "test label shape(66,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 15\n",
      "accuracy is 0.818181818182\n",
      "error is 0.181818181818\n",
      "accuracy is 0.818181818182\n",
      "error is 0.181818181818\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "0.11212121212121208\n"
     ]
    }
   ],
   "source": [
    "trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "    'news_bag_of_words.csv', 'index.csv', '20newsgroups', 1.0)\n",
    "err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(20,)\n",
      "(20, 21)\n",
      "test set..\n",
      "(6, 21)\n",
      "(6,)\n",
      "train set..\n",
      "(14, 21)\n",
      "(14,)\n",
      "trainset shape(14, 21)\n",
      "train label shape(14, 1)\n",
      "testset shape(6, 21)\n",
      "test label shape(6,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.5\n",
      "error is 0.5\n",
      "accuracy is 0.5\n",
      "error is 0.5\n",
      "accuracy is 0.5\n",
      "error is 0.5\n",
      "0.5\n",
      "[0.5]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(40,)\n",
      "(40, 21)\n",
      "test set..\n",
      "(13, 21)\n",
      "(13,)\n",
      "train set..\n",
      "(27, 21)\n",
      "(27,)\n",
      "trainset shape(27, 21)\n",
      "train label shape(27, 1)\n",
      "testset shape(13, 21)\n",
      "test label shape(13,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.384615384615\n",
      "error is 0.615384615385\n",
      "accuracy is 0.384615384615\n",
      "error is 0.615384615385\n",
      "accuracy is 0.384615384615\n",
      "error is 0.615384615385\n",
      "0.6153846153846154\n",
      "[0.5, 0.6153846153846154]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(60,)\n",
      "(60, 21)\n",
      "test set..\n",
      "(20, 21)\n",
      "(20,)\n",
      "train set..\n",
      "(40, 21)\n",
      "(40,)\n",
      "trainset shape(40, 21)\n",
      "train label shape(40, 1)\n",
      "testset shape(20, 21)\n",
      "test label shape(20,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.65\n",
      "error is 0.35\n",
      "accuracy is 0.65\n",
      "error is 0.35\n",
      "accuracy is 0.65\n",
      "error is 0.35\n",
      "0.35\n",
      "[0.5, 0.6153846153846154, 0.35]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(80,)\n",
      "(80, 21)\n",
      "test set..\n",
      "(26, 21)\n",
      "(26,)\n",
      "train set..\n",
      "(54, 21)\n",
      "(54,)\n",
      "trainset shape(54, 21)\n",
      "train label shape(54, 1)\n",
      "testset shape(26, 21)\n",
      "test label shape(26,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.538461538462\n",
      "error is 0.461538461538\n",
      "accuracy is 0.538461538462\n",
      "error is 0.461538461538\n",
      "accuracy is 0.538461538462\n",
      "error is 0.461538461538\n",
      "0.46153846153846156\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(100,)\n",
      "(100, 21)\n",
      "test set..\n",
      "(33, 21)\n",
      "(33,)\n",
      "train set..\n",
      "(67, 21)\n",
      "(67,)\n",
      "trainset shape(67, 21)\n",
      "train label shape(67, 1)\n",
      "testset shape(33, 21)\n",
      "test label shape(33,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.484848484848\n",
      "error is 0.515151515152\n",
      "accuracy is 0.484848484848\n",
      "error is 0.515151515152\n",
      "accuracy is 0.484848484848\n",
      "error is 0.515151515152\n",
      "0.5151515151515151\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(120,)\n",
      "(120, 21)\n",
      "test set..\n",
      "(40, 21)\n",
      "(40,)\n",
      "train set..\n",
      "(80, 21)\n",
      "(80,)\n",
      "trainset shape(80, 21)\n",
      "train label shape(80, 1)\n",
      "testset shape(40, 21)\n",
      "test label shape(40,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.4\n",
      "error is 0.6\n",
      "accuracy is 0.4\n",
      "error is 0.6\n",
      "accuracy is 0.4\n",
      "error is 0.6\n",
      "0.6\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151, 0.6]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(140,)\n",
      "(140, 21)\n",
      "test set..\n",
      "(46, 21)\n",
      "(46,)\n",
      "train set..\n",
      "(94, 21)\n",
      "(94,)\n",
      "trainset shape(94, 21)\n",
      "train label shape(94, 1)\n",
      "testset shape(46, 21)\n",
      "test label shape(46,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.391304347826\n",
      "error is 0.608695652174\n",
      "accuracy is 0.434782608696\n",
      "error is 0.565217391304\n",
      "accuracy is 0.434782608696\n",
      "error is 0.565217391304\n",
      "0.6086956521739131\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151, 0.6, 0.6086956521739131]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(160,)\n",
      "(160, 21)\n",
      "test set..\n",
      "(53, 21)\n",
      "(53,)\n",
      "train set..\n",
      "(107, 21)\n",
      "(107,)\n",
      "trainset shape(107, 21)\n",
      "train label shape(107, 1)\n",
      "testset shape(53, 21)\n",
      "test label shape(53,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.433962264151\n",
      "error is 0.566037735849\n",
      "accuracy is 0.433962264151\n",
      "error is 0.566037735849\n",
      "accuracy is 0.433962264151\n",
      "error is 0.566037735849\n",
      "0.5660377358490566\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151, 0.6, 0.6086956521739131, 0.5660377358490566]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(180,)\n",
      "(180, 21)\n",
      "test set..\n",
      "(60, 21)\n",
      "(60,)\n",
      "train set..\n",
      "(120, 21)\n",
      "(120,)\n",
      "trainset shape(120, 21)\n",
      "train label shape(120, 1)\n",
      "testset shape(60, 21)\n",
      "test label shape(60,)\n",
      "iteration 1\n",
      "iteration 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.516666666667\n",
      "error is 0.483333333333\n",
      "accuracy is 0.516666666667\n",
      "error is 0.483333333333\n",
      "accuracy is 0.516666666667\n",
      "error is 0.483333333333\n",
      "0.4833333333333333\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151, 0.6, 0.6086956521739131, 0.5660377358490566, 0.4833333333333333]\n",
      "(200,)\n",
      "(200, 20)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(200,)\n",
      "(200, 21)\n",
      "test set..\n",
      "(66, 21)\n",
      "(66,)\n",
      "train set..\n",
      "(134, 21)\n",
      "(134,)\n",
      "trainset shape(134, 21)\n",
      "train label shape(134, 1)\n",
      "testset shape(66, 21)\n",
      "test label shape(66,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 3\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "accuracy is 0.545454545455\n",
      "error is 0.454545454545\n",
      "0.4545454545454546\n",
      "[0.5, 0.6153846153846154, 0.35, 0.46153846153846156, 0.5151515151515151, 0.6, 0.6086956521739131, 0.5660377358490566, 0.4833333333333333, 0.4545454545454546]\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "doc_topics_err_list = []\n",
    "for frac in fractions:\n",
    "    trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "        'news_doc_topics.csv', 'index.csv', '20newsgroups', frac)\n",
    "    err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "    print(np.max(err))\n",
    "    doc_topics_err_list.append(np.max(err))\n",
    "\n",
    "    print(doc_topics_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(20,)\n",
      "(20, 406)\n",
      "test set..\n",
      "(6, 406)\n",
      "(6,)\n",
      "train set..\n",
      "(14, 406)\n",
      "(14,)\n",
      "trainset shape(14, 406)\n",
      "train label shape(14, 1)\n",
      "testset shape(6, 406)\n",
      "test label shape(6,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 11\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.666666666667\n",
      "error is 0.333333333333\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "0.33333333333333337\n",
      "[0.33333333333333337]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sahiltyagi/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(40,)\n",
      "(40, 406)\n",
      "test set..\n",
      "(13, 406)\n",
      "(13,)\n",
      "train set..\n",
      "(27, 406)\n",
      "(27,)\n",
      "trainset shape(27, 406)\n",
      "train label shape(27, 1)\n",
      "testset shape(13, 406)\n",
      "test label shape(13,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 12\n",
      "accuracy is 0.769230769231\n",
      "error is 0.230769230769\n",
      "accuracy is 0.769230769231\n",
      "error is 0.230769230769\n",
      "accuracy is 0.769230769231\n",
      "error is 0.230769230769\n",
      "accuracy is 0.769230769231\n",
      "error is 0.230769230769\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "accuracy is 0.846153846154\n",
      "error is 0.153846153846\n",
      "0.23076923076923073\n",
      "[0.33333333333333337, 0.23076923076923073]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(60,)\n",
      "(60, 406)\n",
      "test set..\n",
      "(20, 406)\n",
      "(20,)\n",
      "train set..\n",
      "(40, 406)\n",
      "(40,)\n",
      "trainset shape(40, 406)\n",
      "train label shape(40, 1)\n",
      "testset shape(20, 406)\n",
      "test label shape(20,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 12\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "0.15000000000000002\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(80,)\n",
      "(80, 406)\n",
      "test set..\n",
      "(26, 406)\n",
      "(26,)\n",
      "train set..\n",
      "(54, 406)\n",
      "(54,)\n",
      "trainset shape(54, 406)\n",
      "train label shape(54, 1)\n",
      "testset shape(26, 406)\n",
      "test label shape(26,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 11\n",
      "accuracy is 0.884615384615\n",
      "error is 0.115384615385\n",
      "accuracy is 0.884615384615\n",
      "error is 0.115384615385\n",
      "accuracy is 0.884615384615\n",
      "error is 0.115384615385\n",
      "accuracy is 0.884615384615\n",
      "error is 0.115384615385\n",
      "accuracy is 0.884615384615\n",
      "error is 0.115384615385\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "accuracy is 0.961538461538\n",
      "error is 0.0384615384615\n",
      "0.11538461538461542\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(100,)\n",
      "(100, 406)\n",
      "test set..\n",
      "(33, 406)\n",
      "(33,)\n",
      "train set..\n",
      "(67, 406)\n",
      "(67,)\n",
      "trainset shape(67, 406)\n",
      "train label shape(67, 1)\n",
      "testset shape(33, 406)\n",
      "test label shape(33,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 10\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.878787878788\n",
      "error is 0.121212121212\n",
      "accuracy is 0.878787878788\n",
      "error is 0.121212121212\n",
      "accuracy is 0.878787878788\n",
      "error is 0.121212121212\n",
      "accuracy is 0.878787878788\n",
      "error is 0.121212121212\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "0.12121212121212122\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(120,)\n",
      "(120, 406)\n",
      "test set..\n",
      "(40, 406)\n",
      "(40,)\n",
      "train set..\n",
      "(80, 406)\n",
      "(80,)\n",
      "trainset shape(80, 406)\n",
      "train label shape(80, 1)\n",
      "testset shape(40, 406)\n",
      "test label shape(40,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 9\n",
      "accuracy is 0.75\n",
      "error is 0.25\n",
      "accuracy is 0.775\n",
      "error is 0.225\n",
      "accuracy is 0.775\n",
      "error is 0.225\n",
      "accuracy is 0.775\n",
      "error is 0.225\n",
      "accuracy is 0.775\n",
      "error is 0.225\n",
      "accuracy is 0.825\n",
      "error is 0.175\n",
      "accuracy is 0.825\n",
      "error is 0.175\n",
      "accuracy is 0.825\n",
      "error is 0.175\n",
      "accuracy is 0.825\n",
      "error is 0.175\n",
      "0.25\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122, 0.25]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(140,)\n",
      "(140, 406)\n",
      "test set..\n",
      "(46, 406)\n",
      "(46,)\n",
      "train set..\n",
      "(94, 406)\n",
      "(94,)\n",
      "trainset shape(94, 406)\n",
      "train label shape(94, 1)\n",
      "testset shape(46, 406)\n",
      "test label shape(46,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 15\n",
      "accuracy is 0.826086956522\n",
      "error is 0.173913043478\n",
      "accuracy is 0.826086956522\n",
      "error is 0.173913043478\n",
      "accuracy is 0.826086956522\n",
      "error is 0.173913043478\n",
      "accuracy is 0.826086956522\n",
      "error is 0.173913043478\n",
      "accuracy is 0.826086956522\n",
      "error is 0.173913043478\n",
      "accuracy is 0.847826086957\n",
      "error is 0.152173913043\n",
      "accuracy is 0.847826086957\n",
      "error is 0.152173913043\n",
      "accuracy is 0.847826086957\n",
      "error is 0.152173913043\n",
      "accuracy is 0.869565217391\n",
      "error is 0.130434782609\n",
      "accuracy is 0.869565217391\n",
      "error is 0.130434782609\n",
      "accuracy is 0.869565217391\n",
      "error is 0.130434782609\n",
      "accuracy is 0.913043478261\n",
      "error is 0.0869565217391\n",
      "accuracy is 0.934782608696\n",
      "error is 0.0652173913043\n",
      "accuracy is 0.934782608696\n",
      "error is 0.0652173913043\n",
      "accuracy is 0.934782608696\n",
      "error is 0.0652173913043\n",
      "0.17391304347826086\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122, 0.25, 0.17391304347826086]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(160,)\n",
      "(160, 406)\n",
      "test set..\n",
      "(53, 406)\n",
      "(53,)\n",
      "train set..\n",
      "(107, 406)\n",
      "(107,)\n",
      "trainset shape(107, 406)\n",
      "train label shape(107, 1)\n",
      "testset shape(53, 406)\n",
      "test label shape(53,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 8\n",
      "accuracy is 0.811320754717\n",
      "error is 0.188679245283\n",
      "accuracy is 0.830188679245\n",
      "error is 0.169811320755\n",
      "accuracy is 0.849056603774\n",
      "error is 0.150943396226\n",
      "accuracy is 0.867924528302\n",
      "error is 0.132075471698\n",
      "accuracy is 0.88679245283\n",
      "error is 0.11320754717\n",
      "accuracy is 0.88679245283\n",
      "error is 0.11320754717\n",
      "accuracy is 0.88679245283\n",
      "error is 0.11320754717\n",
      "accuracy is 0.88679245283\n",
      "error is 0.11320754717\n",
      "0.18867924528301883\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122, 0.25, 0.17391304347826086, 0.18867924528301883]\n",
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(180,)\n",
      "(180, 406)\n",
      "test set..\n",
      "(60, 406)\n",
      "(60,)\n",
      "train set..\n",
      "(120, 406)\n",
      "(120,)\n",
      "trainset shape(120, 406)\n",
      "train label shape(120, 1)\n",
      "testset shape(60, 406)\n",
      "test label shape(60,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 15\n",
      "accuracy is 0.816666666667\n",
      "error is 0.183333333333\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.85\n",
      "error is 0.15\n",
      "accuracy is 0.866666666667\n",
      "error is 0.133333333333\n",
      "accuracy is 0.866666666667\n",
      "error is 0.133333333333\n",
      "accuracy is 0.866666666667\n",
      "error is 0.133333333333\n",
      "accuracy is 0.883333333333\n",
      "error is 0.116666666667\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.9\n",
      "error is 0.1\n",
      "accuracy is 0.966666666667\n",
      "error is 0.0333333333333\n",
      "accuracy is 0.966666666667\n",
      "error is 0.0333333333333\n",
      "accuracy is 0.966666666667\n",
      "error is 0.0333333333333\n",
      "accuracy is 0.966666666667\n",
      "error is 0.0333333333333\n",
      "accuracy is 0.966666666667\n",
      "error is 0.0333333333333\n",
      "0.18333333333333335\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122, 0.25, 0.17391304347826086, 0.18867924528301883, 0.18333333333333335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 405)\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "(200,)\n",
      "(200, 406)\n",
      "test set..\n",
      "(66, 406)\n",
      "(66,)\n",
      "train set..\n",
      "(134, 406)\n",
      "(134,)\n",
      "trainset shape(134, 406)\n",
      "train label shape(134, 1)\n",
      "testset shape(66, 406)\n",
      "test label shape(66,)\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! reached threshold...............\n",
      "w_vector_list length is 15\n",
      "accuracy is 0.818181818182\n",
      "error is 0.181818181818\n",
      "accuracy is 0.818181818182\n",
      "error is 0.181818181818\n",
      "accuracy is 0.833333333333\n",
      "error is 0.166666666667\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.863636363636\n",
      "error is 0.136363636364\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.893939393939\n",
      "error is 0.106060606061\n",
      "accuracy is 0.909090909091\n",
      "error is 0.0909090909091\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "accuracy is 0.969696969697\n",
      "error is 0.030303030303\n",
      "0.18181818181818177\n",
      "[0.33333333333333337, 0.23076923076923073, 0.15000000000000002, 0.11538461538461542, 0.12121212121212122, 0.25, 0.17391304347826086, 0.18867924528301883, 0.18333333333333335, 0.18181818181818177]\n"
     ]
    }
   ],
   "source": [
    "fractions = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "bag_of_words_err_list = []\n",
    "for frac in fractions:\n",
    "    trainset_features, trainset_label, testset_features, testset_label = no_randomness_read_input_file_with_added_feature(\n",
    "        'news_bag_of_words.csv', 'index.csv', '20newsgroups', frac)\n",
    "    err, runtime = newtons_method(trainset_features, trainset_label, testset_features, testset_label)\n",
    "    print(np.max(err))\n",
    "    bag_of_words_err_list.append(np.max(err))\n",
    "\n",
    "    print(bag_of_words_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fractions = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "plt.plot(fractions, bag_of_words_err_list, color='b', label='bag of words')\n",
    "plt.plot(fractions, doc_topics_err_list, color='r', label = 'doc topic')\n",
    "\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('training set size')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.3258475776\n"
     ]
    }
   ],
   "source": [
    "b_big = 384\n",
    "b_small = 128\n",
    "g_big = 1.107932387778861\n",
    "g_small = 1.5336734447328282\n",
    "\n",
    "inv_big = float(1)/float(b_big)\n",
    "inv_small = float(1)/float(b_small)\n",
    "\n",
    "G = (b_big*g_big - b_small*g_small)/(b_big - b_small)\n",
    "S = (g_small - g_big)/(inv_small - inv_big)\n",
    "\n",
    "Noise = float(S)/float(G)\n",
    "print(Noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
